2023-03-14T10:29:15.672+0100 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2023-03-14T10:29:15.679+0100 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2023-03-14T10:29:15.680+0100 I  CONTROL  [initandlisten] MongoDB starting : pid=3812 port=27020 dbpath=\data\rs3 64-bit host=DESKTOP-BMALQ1T
2023-03-14T10:29:15.680+0100 I  CONTROL  [initandlisten] targetMinOS: Windows 7/Windows Server 2008 R2
2023-03-14T10:29:15.681+0100 I  CONTROL  [initandlisten] db version v4.2.24
2023-03-14T10:29:15.681+0100 I  CONTROL  [initandlisten] git version: 5e4ec1d24431fcdd28b579a024c5c801b8cde4e2
2023-03-14T10:29:15.681+0100 I  CONTROL  [initandlisten] allocator: tcmalloc
2023-03-14T10:29:15.682+0100 I  CONTROL  [initandlisten] modules: none
2023-03-14T10:29:15.682+0100 I  CONTROL  [initandlisten] build environment:
2023-03-14T10:29:15.682+0100 I  CONTROL  [initandlisten]     distmod: 2012plus
2023-03-14T10:29:15.682+0100 I  CONTROL  [initandlisten]     distarch: x86_64
2023-03-14T10:29:15.682+0100 I  CONTROL  [initandlisten]     target_arch: x86_64
2023-03-14T10:29:15.682+0100 I  CONTROL  [initandlisten] options: { net: { port: 27020 }, replication: { replSet: "myRepl" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "\data\rs3" }, systemLog: { destination: "file", path: "\data\rs3\3.log" } }
2023-03-14T10:29:15.684+0100 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=3521M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2023-03-14T10:29:15.903+0100 I  STORAGE  [initandlisten] WiredTiger message [1678786155:902496][3812:140715784624944], txn-recover: Set global recovery timestamp: (0, 0)
2023-03-14T10:29:16.104+0100 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2023-03-14T10:29:16.292+0100 I  STORAGE  [initandlisten] Timestamp monitor starting
2023-03-14T10:29:16.351+0100 I  CONTROL  [initandlisten] 
2023-03-14T10:29:16.352+0100 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2023-03-14T10:29:16.352+0100 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2023-03-14T10:29:16.353+0100 I  CONTROL  [initandlisten] 
2023-03-14T10:29:16.354+0100 I  CONTROL  [initandlisten] ** WARNING: This server is bound to localhost.
2023-03-14T10:29:16.354+0100 I  CONTROL  [initandlisten] **          Remote systems will be unable to connect to this server. 
2023-03-14T10:29:16.354+0100 I  CONTROL  [initandlisten] **          Start the server with --bind_ip <address> to specify which IP 
2023-03-14T10:29:16.355+0100 I  CONTROL  [initandlisten] **          addresses it should serve responses from, or with --bind_ip_all to
2023-03-14T10:29:16.355+0100 I  CONTROL  [initandlisten] **          bind to all interfaces. If this behavior is desired, start the
2023-03-14T10:29:16.355+0100 I  CONTROL  [initandlisten] **          server with --bind_ip 127.0.0.1 to disable this warning.
2023-03-14T10:29:16.356+0100 I  CONTROL  [initandlisten] 
2023-03-14T10:29:16.359+0100 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2023-03-14T10:29:16.361+0100 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 9f12cf67-857f-4235-90d1-fc2feee0a043 and options: { capped: true, size: 10485760 }
2023-03-14T10:29:16.503+0100 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2023-03-14T10:29:17.058+0100 W  FTDC     [initandlisten] Failed to initialize Performance Counters for FTDC: WindowsPdhError: PdhExpandCounterPathW failed with 'L’objet spécifié n’a pas été trouvé sur l’ordinateur.' for counter '\Memory\Available Bytes'
2023-03-14T10:29:17.059+0100 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/rs3/diagnostic.data'
2023-03-14T10:29:17.061+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2023-03-14T10:29:17.061+0100 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2023-03-14T10:29:17.062+0100 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 6d99b567-662b-42a3-be4b-87f8f961bc25 and options: {}
2023-03-14T10:29:17.169+0100 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2023-03-14T10:29:17.169+0100 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 47a596f4-92df-4923-a04d-4b2645905578 and options: {}
2023-03-14T10:29:17.280+0100 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2023-03-14T10:29:17.281+0100 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 35d29964-42a7-47b4-8607-faa90a36df6f and options: {}
2023-03-14T10:29:17.451+0100 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2023-03-14T10:29:17.452+0100 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2023-03-14T10:29:17.453+0100 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2023-03-14T10:29:17.453+0100 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 78c3618c-3641-497a-87d1-8d0b8b96f143 and options: {}
2023-03-14T10:29:17.559+0100 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2023-03-14T10:29:17.560+0100 I  REPL     [initandlisten] Initialized the rollback ID to 1
2023-03-14T10:29:17.561+0100 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2023-03-14T10:29:17.566+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("3d306b79-6268-420f-928c-176c8fcc3e8a"), lastMod: 0 } took 0 ms
2023-03-14T10:29:17.567+0100 I  NETWORK  [listener] Listening on 127.0.0.1
2023-03-14T10:29:17.567+0100 I  NETWORK  [listener] waiting for connections on port 27020
2023-03-14T10:29:17.567+0100 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2023-03-14T10:29:17.567+0100 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2023-03-14T10:29:17.568+0100 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2023-03-14T10:29:47.062+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2023-03-14T10:30:17.062+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2023-03-14T10:30:47.064+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2023-03-14T10:31:17.064+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2023-03-14T10:31:47.064+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2023-03-14T10:32:17.065+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2023-03-14T10:32:32.611+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:58447 #1 (1 connection now open)
2023-03-14T10:32:32.612+0100 I  NETWORK  [conn1] end connection 127.0.0.1:58447 (0 connections now open)
2023-03-14T10:32:32.648+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:58449 #2 (1 connection now open)
2023-03-14T10:32:32.649+0100 I  NETWORK  [conn2] received client metadata from 127.0.0.1:58449 conn2: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:32:32.681+0100 I  CONNPOOL [Replication] Connecting to localhost:27018
2023-03-14T10:32:33.734+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:58455 #6 (2 connections now open)
2023-03-14T10:32:33.738+0100 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: 4e4bad02-b40a-4cf8-a019-317e13ebc2ae and options: {}
2023-03-14T10:32:33.744+0100 I  NETWORK  [conn6] end connection 127.0.0.1:58455 (1 connection now open)
2023-03-14T10:32:33.961+0100 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2023-03-14T10:32:33.962+0100 I  REPL     [replexec-0] New replica set config in use: { _id: "myRepl", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "localhost:27018", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "localhost:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 3, host: "localhost:27020", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('64103f30098823e91edb78e7') } }
2023-03-14T10:32:33.963+0100 I  REPL     [replexec-0] This node is localhost:27020 in the config
2023-03-14T10:32:33.963+0100 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2023-03-14T10:32:33.965+0100 I  REPL     [replexec-0] Starting replication storage threads
2023-03-14T10:32:33.966+0100 I  CONNPOOL [Replication] Connecting to localhost:27019
2023-03-14T10:32:33.967+0100 I  REPL     [replexec-1] Member localhost:27018 is now in state SECONDARY
2023-03-14T10:32:33.973+0100 I  REPL     [replexec-2] Member localhost:27019 is now in state STARTUP
2023-03-14T10:32:33.976+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:58457 #8 (2 connections now open)
2023-03-14T10:32:33.983+0100 I  NETWORK  [conn8] received client metadata from 127.0.0.1:58457 conn8: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:32:34.052+0100 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: 79da6a8c-d149-4543-b173-600aa75bea93 and options: { temp: true }
2023-03-14T10:32:34.282+0100 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2023-03-14T10:32:34.283+0100 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2023-03-14T10:32:34.326+0100 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (79da6a8c-d149-4543-b173-600aa75bea93).
2023-03-14T10:32:34.427+0100 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: effcfd52-94f0-4979-a495-64e5b2af7717 and options: { temp: true }
2023-03-14T10:32:34.474+0100 I  REPL     [replexec-0] Member localhost:27019 is now in state STARTUP2
2023-03-14T10:32:34.730+0100 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2023-03-14T10:32:34.731+0100 I  REPL     [replication-0] sync source candidate: localhost:27018
2023-03-14T10:32:34.732+0100 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2023-03-14T10:32:34.733+0100 I  REPL     [replication-0] ******
2023-03-14T10:32:34.733+0100 I  REPL     [replication-0] creating replication oplog of size: 26459MB...
2023-03-14T10:32:34.733+0100 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: 656fc7f8-8b91-4cbc-a2dc-e24cf48d7c5c and options: { capped: true, size: 27745057792.0, autoIndexId: false }
2023-03-14T10:32:34.849+0100 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2023-03-14T10:32:34.850+0100 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2023-03-14T10:32:34.850+0100 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2023-03-14T10:32:34.850+0100 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2023-03-14T10:32:35.815+0100 I  REPL     [replication-0] ******
2023-03-14T10:32:35.816+0100 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2023-03-14T10:32:35.816+0100 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2023-03-14T10:32:35.818+0100 I  CONNPOOL [RS] Connecting to localhost:27018
2023-03-14T10:32:35.972+0100 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:admin.system.version
2023-03-14T10:32:35.992+0100 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: fd1a66e9-9851-49f5-821c-f90779f76ebe and options: { uuid: UUID("fd1a66e9-9851-49f5-821c-f90779f76ebe") }
2023-03-14T10:32:36.361+0100 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2023-03-14T10:32:36.361+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:36.400+0100 I  COMMAND  [repl-writer-worker-0] setting featureCompatibilityVersion to 4.2
2023-03-14T10:32:36.400+0100 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 8
2023-03-14T10:32:36.401+0100 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 2
2023-03-14T10:32:36.401+0100 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.version finished cloning with status: OK
2023-03-14T10:32:36.404+0100 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
2023-03-14T10:32:36.507+0100 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.version
2023-03-14T10:32:36.527+0100 I  INITSYNC [replication-0] Finished cloning data: OK. Beginning oplog replay.
2023-03-14T10:32:36.528+0100 I  INITSYNC [replication-1] No need to apply operations. (currently at { : Timestamp(1678786353, 1) })
2023-03-14T10:32:36.529+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "replset.election" }
2023-03-14T10:32:36.529+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "replset.minvalid" }
2023-03-14T10:32:36.530+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "system.replset" }
2023-03-14T10:32:36.530+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "oplog.rs" }
2023-03-14T10:32:36.530+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "replset.oplogTruncateAfterPoint" }
2023-03-14T10:32:36.530+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "system.rollback.id" }
2023-03-14T10:32:36.530+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "startup_log" }
2023-03-14T10:32:36.530+0100 I  COMMAND  [replication-0] CMD: collMod: { collMod: "temp_oplog_buffer" }
2023-03-14T10:32:36.557+0100 I  INITSYNC [replication-0] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(0, 0), t: -1 }
2023-03-14T10:32:36.558+0100 I  INITSYNC [replication-0] Initial sync attempt finishing up.
2023-03-14T10:32:36.558+0100 I  INITSYNC [replication-0] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1678786354283), totalInitialSyncElapsedMillis: 2275, initialSyncAttempts: [], approxTotalDataSize: 59, approxTotalBytesCopied: 59, remainingInitialSyncEstimatedMillis: 0, fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1678786353, 1), initialSyncOplogEnd: Timestamp(1678786353, 1), databases: { databasesToClone: 0, databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1678786355958), end: new Date(1678786356528), elapsedMillis: 570, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, bytesToCopy: 59, approxBytesCopied: 59, start: new Date(1678786355973), end: new Date(1678786356528), elapsedMillis: 555, receivedBatches: 1 } } } }
2023-03-14T10:32:36.559+0100 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (effcfd52-94f0-4979-a495-64e5b2af7717).
2023-03-14T10:32:36.650+0100 I  CONNPOOL [RS] Ending connection to host localhost:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2023-03-14T10:32:36.836+0100 I  INITSYNC [replication-0] initial sync done; took 2s.
2023-03-14T10:32:36.837+0100 I  REPL     [replication-0] transition to RECOVERING from STARTUP2
2023-03-14T10:32:36.837+0100 I  REPL     [replication-0] Starting replication fetcher thread
2023-03-14T10:32:36.837+0100 I  REPL     [replication-0] Starting replication applier thread
2023-03-14T10:32:36.837+0100 I  REPL     [replication-0] Starting replication reporter thread
2023-03-14T10:32:36.837+0100 I  REPL     [rsSync-0] Starting oplog application
2023-03-14T10:32:36.837+0100 I  REPL     [rsBackgroundSync] could not find member to sync from
2023-03-14T10:32:36.844+0100 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2023-03-14T10:32:36.845+0100 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2023-03-14T10:32:37.343+0100 I  REPL     [replexec-4] Member localhost:27019 is now in state SECONDARY
2023-03-14T10:32:44.920+0100 I  ELECTION [conn2] Received vote request: { replSetRequestVotes: 1, setName: "myRepl", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1678786353, 1), t: -1 } }
2023-03-14T10:32:44.921+0100 I  ELECTION [conn2] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2023-03-14T10:32:45.007+0100 I  ELECTION [conn2] Received vote request: { replSetRequestVotes: 1, setName: "myRepl", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1678786353, 1), t: -1 } }
2023-03-14T10:32:45.007+0100 I  ELECTION [conn2] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2023-03-14T10:32:45.039+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:58467 #13 (3 connections now open)
2023-03-14T10:32:45.040+0100 I  NETWORK  [conn13] received client metadata from 127.0.0.1:58467 conn13: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:32:45.070+0100 I  NETWORK  [conn2] end connection 127.0.0.1:58449 (2 connections now open)
2023-03-14T10:32:45.403+0100 I  REPL     [replexec-1] Member localhost:27018 is now in state PRIMARY
2023-03-14T10:32:45.859+0100 I  REPL     [rsBackgroundSync] sync source candidate: localhost:27018
2023-03-14T10:32:47.065+0100 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2023-03-14T10:32:50.050+0100 I  REPL     [rsBackgroundSync] Changed sync source from empty to localhost:27018
2023-03-14T10:32:50.052+0100 I  CONNPOOL [RS] Connecting to localhost:27018
2023-03-14T10:32:50.071+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.transactions with provided UUID: 47b3fb26-a0c8-4c87-a87a-67476dec8ae2 and options: { uuid: UUID("47b3fb26-a0c8-4c87-a87a-67476dec8ae2") }
2023-03-14T10:32:50.326+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.transactions
2023-03-14T10:32:50.327+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786365, 2), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("47b3fb26-a0c8-4c87-a87a-67476dec8ae2"), wall: new Date(1678786365181), o: { create: "transactions", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.transactions" } } }, took 256ms
2023-03-14T10:32:50.331+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.image_collection with provided UUID: 6445f0e8-7d80-401d-8e3e-86a04131ea2d and options: { uuid: UUID("6445f0e8-7d80-401d-8e3e-86a04131ea2d") }
2023-03-14T10:32:50.594+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.image_collection
2023-03-14T10:32:50.594+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786365, 3), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("6445f0e8-7d80-401d-8e3e-86a04131ea2d"), wall: new Date(1678786365293), o: { create: "image_collection", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.image_collection" } } }, took 263ms
2023-03-14T10:32:50.599+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.chunks with provided UUID: b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 and options: { uuid: UUID("b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6") }
2023-03-14T10:32:51.097+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.chunks
2023-03-14T10:32:51.098+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786365, 5), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6"), wall: new Date(1678786365404), o: { create: "chunks", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.chunks" } } }, took 499ms
2023-03-14T10:32:51.760+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2023-03-14T10:32:51.760+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:51.760+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 63e0aa45-f913-48a1-b492-f94f93c6dc3a: config.chunks (b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 ): indexes: 1
2023-03-14T10:32:51.761+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786365, 7), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6"), wall: new Date(1678786365613), o: { createIndexes: "chunks", v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1" } }, took 656ms
2023-03-14T10:32:51.762+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:51.771+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:51.907+0100 I  STORAGE  [replexec-3] Triggering the first stable checkpoint. Initial Data: Timestamp(1678786353, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1678786365, 8)
2023-03-14T10:32:51.914+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.chunks
2023-03-14T10:32:52.071+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 63e0aa45-f913-48a1-b492-f94f93c6dc3a: config.chunks ( b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2023-03-14T10:32:53.183+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2023-03-14T10:32:53.183+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:53.184+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: f680c32a-c439-4bf4-ba74-23b48af7646d: config.chunks (b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 ): indexes: 1
2023-03-14T10:32:53.184+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786365, 9), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6"), wall: new Date(1678786365935), o: { createIndexes: "chunks", v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1" } }, took 1413ms
2023-03-14T10:32:53.184+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:53.185+0100 W  STORAGE  [IndexBuildsCoordinatorMongod-0] failed to create WiredTiger bulk cursor: Resource device
2023-03-14T10:32:53.185+0100 W  STORAGE  [IndexBuildsCoordinatorMongod-0] falling back to non-bulk cursor for index table:index-28--2397834349295642681
2023-03-14T10:32:53.186+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:53.187+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2023-03-14T10:32:53.727+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: f680c32a-c439-4bf4-ba74-23b48af7646d: config.chunks ( b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2023-03-14T10:32:54.463+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2023-03-14T10:32:54.463+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:54.463+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 93094b3f-2409-4f7f-9678-2c0016bdf4c4: config.chunks (b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 ): indexes: 1
2023-03-14T10:32:54.463+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786366, 2), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6"), wall: new Date(1678786366329), o: { createIndexes: "chunks", v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1" } }, took 1271ms
2023-03-14T10:32:54.464+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:54.466+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.migrations with provided UUID: bfb368bc-88bc-461c-b869-4d8a2ab083da and options: { uuid: UUID("bfb368bc-88bc-461c-b869-4d8a2ab083da") }
2023-03-14T10:32:54.468+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:54.686+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2023-03-14T10:32:54.838+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.migrations
2023-03-14T10:32:54.838+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786366, 3), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("bfb368bc-88bc-461c-b869-4d8a2ab083da"), wall: new Date(1678786366614), o: { create: "migrations", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.migrations" } } }, took 372ms
2023-03-14T10:32:55.015+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 93094b3f-2409-4f7f-9678-2c0016bdf4c4: config.chunks ( b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6 ). Index specs built: 1. Indexes in catalog before build: 3. Indexes in catalog after build: 4
2023-03-14T10:32:55.385+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2023-03-14T10:32:55.415+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:55.416+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 87148adb-f43d-442b-bf40-a3428a13e483: config.migrations (bfb368bc-88bc-461c-b869-4d8a2ab083da ): indexes: 1
2023-03-14T10:32:55.416+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786367, 1), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("bfb368bc-88bc-461c-b869-4d8a2ab083da"), wall: new Date(1678786367034), o: { createIndexes: "migrations", v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1" } }, took 574ms
2023-03-14T10:32:55.416+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:55.420+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.shards with provided UUID: 25d0c6fe-2dbb-42d8-b789-7b7a61fe0e07 and options: { uuid: UUID("25d0c6fe-2dbb-42d8-b789-7b7a61fe0e07") }
2023-03-14T10:32:55.421+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:55.592+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.migrations
2023-03-14T10:32:56.015+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.shards
2023-03-14T10:32:56.015+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786367, 2), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("25d0c6fe-2dbb-42d8-b789-7b7a61fe0e07"), wall: new Date(1678786367476), o: { create: "shards", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.shards" } } }, took 595ms
2023-03-14T10:32:56.070+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 87148adb-f43d-442b-bf40-a3428a13e483: config.migrations ( bfb368bc-88bc-461c-b869-4d8a2ab083da ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2023-03-14T10:32:56.605+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2023-03-14T10:32:56.605+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:56.606+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 65a136af-b98a-4c1b-96c1-bd5cfcc78da1: config.shards (25d0c6fe-2dbb-42d8-b789-7b7a61fe0e07 ): indexes: 1
2023-03-14T10:32:56.606+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786367, 4), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("25d0c6fe-2dbb-42d8-b789-7b7a61fe0e07"), wall: new Date(1678786367859), o: { createIndexes: "shards", v: 2, unique: true, key: { host: 1 }, name: "host_1" } }, took 588ms
2023-03-14T10:32:56.606+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:56.611+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.locks with provided UUID: 53531bb5-d945-406e-b92c-c47d324cfaea and options: { uuid: UUID("53531bb5-d945-406e-b92c-c47d324cfaea") }
2023-03-14T10:32:56.613+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:56.916+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index host_1 on ns config.shards
2023-03-14T10:32:57.121+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.locks
2023-03-14T10:32:57.122+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786367, 5), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("53531bb5-d945-406e-b92c-c47d324cfaea"), wall: new Date(1678786368082), o: { create: "locks", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.locks" } } }, took 510ms
2023-03-14T10:32:57.305+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 65a136af-b98a-4c1b-96c1-bd5cfcc78da1: config.shards ( 25d0c6fe-2dbb-42d8-b789-7b7a61fe0e07 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2023-03-14T10:32:57.526+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2023-03-14T10:32:57.526+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:57.527+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 226e4511-f896-4244-9419-f7eb9924ec54: config.locks (53531bb5-d945-406e-b92c-c47d324cfaea ): indexes: 1
2023-03-14T10:32:57.527+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786368, 2), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("53531bb5-d945-406e-b92c-c47d324cfaea"), wall: new Date(1678786368315), o: { createIndexes: "locks", v: 2, key: { ts: 1 }, name: "ts_1" } }, took 399ms
2023-03-14T10:32:57.527+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:57.531+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:57.615+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ts_1 on ns config.locks
2023-03-14T10:32:57.683+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 226e4511-f896-4244-9419-f7eb9924ec54: config.locks ( 53531bb5-d945-406e-b92c-c47d324cfaea ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2023-03-14T10:32:57.977+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2023-03-14T10:32:57.978+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:57.979+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 976bb6d0-5771-45b7-9b1f-6e74ddaf4d55: config.locks (53531bb5-d945-406e-b92c-c47d324cfaea ): indexes: 1
2023-03-14T10:32:57.979+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786368, 4), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("53531bb5-d945-406e-b92c-c47d324cfaea"), wall: new Date(1678786368548), o: { createIndexes: "locks", v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1" } }, took 448ms
2023-03-14T10:32:57.980+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:57.986+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.lockpings with provided UUID: d771fd14-cba4-42bc-b7bb-b69697ff3b0a and options: { uuid: UUID("d771fd14-cba4-42bc-b7bb-b69697ff3b0a") }
2023-03-14T10:32:57.987+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:58.373+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index state_1_process_1 on ns config.locks
2023-03-14T10:32:58.505+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.lockpings
2023-03-14T10:32:58.506+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786368, 5), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("d771fd14-cba4-42bc-b7bb-b69697ff3b0a"), wall: new Date(1678786368759), o: { create: "lockpings", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.lockpings" } } }, took 521ms
2023-03-14T10:32:58.583+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 976bb6d0-5771-45b7-9b1f-6e74ddaf4d55: config.locks ( 53531bb5-d945-406e-b92c-c47d324cfaea ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2023-03-14T10:32:58.973+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2023-03-14T10:32:58.974+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:32:58.974+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: d286a9b6-afc3-42ec-b757-8e0b438da446: config.lockpings (d771fd14-cba4-42bc-b7bb-b69697ff3b0a ): indexes: 1
2023-03-14T10:32:58.974+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786368, 7), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("d771fd14-cba4-42bc-b7bb-b69697ff3b0a"), wall: new Date(1678786368918), o: { createIndexes: "lockpings", v: 2, key: { ping: 1 }, name: "ping_1" } }, took 462ms
2023-03-14T10:32:58.974+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:32:58.976+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.tags with provided UUID: 15d7e9ec-db7f-4b52-b979-664915541c05 and options: { uuid: UUID("15d7e9ec-db7f-4b52-b979-664915541c05") }
2023-03-14T10:32:58.978+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:32:59.248+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ping_1 on ns config.lockpings
2023-03-14T10:32:59.418+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.tags
2023-03-14T10:32:59.419+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786368, 8), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("15d7e9ec-db7f-4b52-b979-664915541c05"), wall: new Date(1678786369160), o: { create: "tags", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.tags" } } }, took 443ms
2023-03-14T10:32:59.467+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: d286a9b6-afc3-42ec-b757-8e0b438da446: config.lockpings ( d771fd14-cba4-42bc-b7bb-b69697ff3b0a ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2023-03-14T10:33:00.061+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2023-03-14T10:33:00.061+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:33:00.061+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 8aea1522-241f-427b-8681-283087f563a5: config.tags (15d7e9ec-db7f-4b52-b979-664915541c05 ): indexes: 1
2023-03-14T10:33:00.061+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786369, 2), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("15d7e9ec-db7f-4b52-b979-664915541c05"), wall: new Date(1678786369417), o: { createIndexes: "tags", v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1" } }, took 628ms
2023-03-14T10:33:00.061+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:33:00.065+0100 I  CONNPOOL [RS] Connecting to localhost:27018
2023-03-14T10:33:00.066+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:33:00.193+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.tags
2023-03-14T10:33:00.416+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 8aea1522-241f-427b-8681-283087f563a5: config.tags ( 15d7e9ec-db7f-4b52-b979-664915541c05 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2023-03-14T10:33:00.772+0100 I  INDEX    [repl-writer-worker-0] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2023-03-14T10:33:00.772+0100 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2023-03-14T10:33:00.772+0100 I  STORAGE  [repl-writer-worker-0] Index build initialized: 73eead3c-91c3-41e9-83c9-9d958f0bb600: config.tags (15d7e9ec-db7f-4b52-b979-664915541c05 ): indexes: 1
2023-03-14T10:33:00.773+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786369, 4), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("15d7e9ec-db7f-4b52-b979-664915541c05"), wall: new Date(1678786369714), o: { createIndexes: "tags", v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1" } }, took 708ms
2023-03-14T10:33:00.773+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2023-03-14T10:33:00.777+0100 I  STORAGE  [repl-writer-worker-0] createCollection: config.version with provided UUID: 1d38f1af-3c2d-4493-8903-ff406d1a2731 and options: { uuid: UUID("1d38f1af-3c2d-4493-8903-ff406d1a2731") }
2023-03-14T10:33:00.781+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2023-03-14T10:33:00.993+0100 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_tag_1 on ns config.tags
2023-03-14T10:33:01.187+0100 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.version
2023-03-14T10:33:01.187+0100 I  REPL     [repl-writer-worker-0] applied op: command { ts: Timestamp(1678786369, 5), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("1d38f1af-3c2d-4493-8903-ff406d1a2731"), wall: new Date(1678786369916), o: { create: "version", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.version" } } }, took 410ms
2023-03-14T10:33:01.239+0100 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 73eead3c-91c3-41e9-83c9-9d958f0bb600: config.tags ( 15d7e9ec-db7f-4b52-b979-664915541c05 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2023-03-14T10:33:01.752+0100 I  STORAGE  [repl-writer-worker-1] createCollection: admin.system.keys with provided UUID: fc36d407-b760-41c2-93c6-353be760f85f and options: { uuid: UUID("fc36d407-b760-41c2-93c6-353be760f85f") }
2023-03-14T10:33:02.049+0100 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns admin.system.keys
2023-03-14T10:33:02.050+0100 I  REPL     [repl-writer-worker-1] applied op: command { ts: Timestamp(1678786381, 1), t: 1, h: 0, v: 2, op: "c", ns: "admin.$cmd", ui: UUID("fc36d407-b760-41c2-93c6-353be760f85f"), wall: new Date(1678786381718), o: { create: "system.keys", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.keys" } } }, took 298ms
2023-03-14T10:33:02.204+0100 I  COMMAND  [monitoring-keys-for-HMAC] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, $readPreference: { mode: "nearest", tags: [] }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 hasSortStage:1 cursorExhausted:1 numYields:2 nreturned:1 queryHash:6DC32749 planCacheKey:6DC32749 reslen:408 locks:{ ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 3 } }, Database: { acquireCount: { r: 3 }, acquireWaitCount: { r: 3 }, timeAcquiringMicros: { r: 286502 } }, Collection: { acquireCount: { r: 3 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 439ms
2023-03-14T10:33:51.420+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:65144 #16 (3 connections now open)
2023-03-14T10:33:51.429+0100 I  NETWORK  [conn16] received client metadata from 127.0.0.1:65144 conn16: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:33:53.874+0100 I  NETWORK  [conn16] end connection 127.0.0.1:65144 (2 connections now open)
2023-03-14T10:34:00.066+0100 I  CONNPOOL [RS] Ending idle connection to host localhost:27018 because the pool meets constraints; 2 connections to that host remain open
2023-03-14T10:34:17.566+0100 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2023-03-14T10:34:17.567+0100 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2023-03-14T10:34:17.568+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-1] Refresh for collection config.system.sessions took 1 ms and found the collection is not sharded
2023-03-14T10:34:17.568+0100 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2023-03-14T10:39:10.480+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:52861 #17 (3 connections now open)
2023-03-14T10:39:10.480+0100 I  NETWORK  [conn17] end connection 127.0.0.1:52861 (2 connections now open)
2023-03-14T10:39:10.482+0100 I  NETWORK  [conn13] end connection 127.0.0.1:58467 (1 connection now open)
2023-03-14T10:39:10.483+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:52862 #18 (2 connections now open)
2023-03-14T10:39:10.484+0100 I  NETWORK  [conn18] received client metadata from 127.0.0.1:52862 conn18: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:39:10.496+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:52866 #21 (3 connections now open)
2023-03-14T10:39:10.497+0100 I  NETWORK  [conn21] end connection 127.0.0.1:52866 (2 connections now open)
2023-03-14T10:39:10.499+0100 I  REPL     [replexec-7] New replica set config in use: { _id: "myRepl", version: 2, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "localhost:27018", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "localhost:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 3, host: "localhost:27020", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('64103f30098823e91edb78e7') } }
2023-03-14T10:39:10.499+0100 I  REPL     [replexec-7] This node is localhost:27020 in the config
2023-03-14T10:39:17.568+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-2] Refresh for collection config.system.sessions took 1 ms and found the collection is not sharded
2023-03-14T10:39:17.568+0100 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2023-03-14T10:39:17.568+0100 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2023-03-14T10:39:17.569+0100 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2023-03-14T10:44:17.568+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-3] Refresh for collection config.system.sessions took 1 ms and found the collection is not sharded
2023-03-14T10:44:17.569+0100 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2023-03-14T10:44:17.569+0100 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2023-03-14T10:44:17.569+0100 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2023-03-14T10:49:17.568+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-4] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2023-03-14T10:49:17.568+0100 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2023-03-14T10:49:17.568+0100 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2023-03-14T10:49:17.568+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-4] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2023-03-14T10:49:17.568+0100 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2023-03-14T10:52:23.518+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53050 #22 (3 connections now open)
2023-03-14T10:52:23.523+0100 I  NETWORK  [conn22] received client metadata from 127.0.0.1:53050 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:52:23.548+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53057 #23 (4 connections now open)
2023-03-14T10:52:23.548+0100 I  NETWORK  [conn23] received client metadata from 127.0.0.1:53057 conn23: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:52:24.243+0100 I  STORAGE  [repl-writer-worker-1] createCollection: config.mongos with provided UUID: 7483451b-14a2-44a4-a819-6a4a34b8caff and options: { uuid: UUID("7483451b-14a2-44a4-a819-6a4a34b8caff") }
2023-03-14T10:52:24.545+0100 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns config.mongos
2023-03-14T10:52:24.546+0100 I  REPL     [repl-writer-worker-1] applied op: command { ts: Timestamp(1678787544, 1), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("7483451b-14a2-44a4-a819-6a4a34b8caff"), wall: new Date(1678787544189), o: { create: "mongos", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.mongos" } } }, took 303ms
2023-03-14T10:52:51.983+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53061 #24 (5 connections now open)
2023-03-14T10:52:51.984+0100 I  NETWORK  [conn24] received client metadata from 127.0.0.1:53061 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:52:52.443+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53066 #25 (6 connections now open)
2023-03-14T10:52:52.445+0100 I  NETWORK  [conn25] received client metadata from 127.0.0.1:53066 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:53:19.014+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53074 #26 (7 connections now open)
2023-03-14T10:53:19.015+0100 I  NETWORK  [conn26] received client metadata from 127.0.0.1:53074 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:54:17.569+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-5] Refresh for collection config.system.sessions took 1 ms and found the collection is not sharded
2023-03-14T10:54:17.570+0100 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2023-03-14T10:54:17.570+0100 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2023-03-14T10:54:17.571+0100 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2023-03-14T10:54:51.650+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53101 #27 (8 connections now open)
2023-03-14T10:54:51.652+0100 I  NETWORK  [conn27] received client metadata from 127.0.0.1:53101 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:03.533+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53105 #28 (9 connections now open)
2023-03-14T10:55:03.533+0100 I  NETWORK  [conn28] received client metadata from 127.0.0.1:53105 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:03.543+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53112 #29 (10 connections now open)
2023-03-14T10:55:03.544+0100 I  NETWORK  [conn29] received client metadata from 127.0.0.1:53112 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:04.409+0100 I  STORAGE  [repl-writer-worker-1] createCollection: config.changelog with provided UUID: db840547-4ed1-499a-83c1-cfc6d4cdbbdd and options: { uuid: UUID("db840547-4ed1-499a-83c1-cfc6d4cdbbdd"), capped: true, size: 209715200 }
2023-03-14T10:55:04.801+0100 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns config.changelog
2023-03-14T10:55:04.802+0100 I  REPL     [repl-writer-worker-1] applied op: command { ts: Timestamp(1678787703, 4), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("db840547-4ed1-499a-83c1-cfc6d4cdbbdd"), wall: new Date(1678787704312), o: { create: "changelog", capped: true, size: 209715200, idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.changelog" } } }, took 393ms
2023-03-14T10:55:20.391+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53117 #30 (11 connections now open)
2023-03-14T10:55:20.391+0100 I  NETWORK  [conn30] received client metadata from 127.0.0.1:53117 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:20.404+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53125 #31 (12 connections now open)
2023-03-14T10:55:20.404+0100 I  NETWORK  [conn31] received client metadata from 127.0.0.1:53125 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:36.089+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53130 #32 (13 connections now open)
2023-03-14T10:55:36.091+0100 I  NETWORK  [conn32] received client metadata from 127.0.0.1:53130 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:36.097+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53135 #33 (14 connections now open)
2023-03-14T10:55:36.098+0100 I  NETWORK  [conn33] received client metadata from 127.0.0.1:53135 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:55:36.101+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53137 #34 (15 connections now open)
2023-03-14T10:55:36.102+0100 I  NETWORK  [conn34] received client metadata from 127.0.0.1:53137 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T10:56:36.100+0100 I  NETWORK  [conn33] end connection 127.0.0.1:53135 (14 connections now open)
2023-03-14T10:58:47.342+0100 I  REPL     [repl-writer-worker-3] applied op: CRUD { ts: Timestamp(1678787927, 1), t: 1, h: 0, v: 2, op: "i", ns: "config.chunks", ui: UUID("b2c8a6e0-9f7f-4ca4-bb1a-2a35c1f169c6"), wall: new Date(1678787927147), lsid: { id: UUID("ec94af93-db29-4a47-8be4-65f791f1f195"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 0, stmtId: 0, prevOpTime: { ts: Timestamp(0, 0), t: -1 }, o: { _id: "config.system.sessions-_id_MinKey", ns: "config.system.sessions", min: { _id: MinKey }, max: { _id: MaxKey }, shard: "shard0000", lastmod: Timestamp(1, 0), lastmodEpoch: ObjectId('641045573504a86837985c0f'), history: [ { validAfter: Timestamp(1678787926, 3), shard: "shard0000" } ] } }, took 138ms
2023-03-14T10:58:47.345+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678787927198) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 146264 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 146ms
2023-03-14T10:58:47.882+0100 I  STORAGE  [repl-writer-worker-3] createCollection: config.collections with provided UUID: 2b3f3460-2627-4239-8a41-903186966dda and options: { uuid: UUID("2b3f3460-2627-4239-8a41-903186966dda") }
2023-03-14T10:58:48.776+0100 I  INDEX    [repl-writer-worker-3] index build: done building index _id_ on ns config.collections
2023-03-14T10:58:48.776+0100 I  REPL     [repl-writer-worker-3] applied op: command { ts: Timestamp(1678787927, 3), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("2b3f3460-2627-4239-8a41-903186966dda"), wall: new Date(1678787927766), o: { create: "collections", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.collections" } } }, took 895ms
2023-03-14T10:58:51.563+0100 I  STORAGE  [repl-writer-worker-3] createCollection: config.system.sessions with provided UUID: ee6b472f-1317-4bd4-b436-668bbf45da0b and options: { uuid: UUID("ee6b472f-1317-4bd4-b436-668bbf45da0b") }
2023-03-14T10:58:51.993+0100 I  INDEX    [repl-writer-worker-3] index build: done building index _id_ on ns config.system.sessions
2023-03-14T10:58:51.995+0100 I  REPL     [repl-writer-worker-3] applied op: command { ts: Timestamp(1678787930, 4), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("ee6b472f-1317-4bd4-b436-668bbf45da0b"), wall: new Date(1678787931503), o: { create: "system.sessions", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.system.sessions" } } }, took 431ms
2023-03-14T10:58:58.046+0100 I  STORAGE  [repl-writer-worker-6] createCollection: config.actionlog with provided UUID: 1be44a09-0fbd-4a16-96a8-25669f03a7cb and options: { uuid: UUID("1be44a09-0fbd-4a16-96a8-25669f03a7cb"), capped: true, size: 20971520 }
2023-03-14T10:58:58.545+0100 I  INDEX    [repl-writer-worker-6] index build: done building index _id_ on ns config.actionlog
2023-03-14T10:58:58.546+0100 I  REPL     [repl-writer-worker-6] applied op: command { ts: Timestamp(1678787937, 4), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("1be44a09-0fbd-4a16-96a8-25669f03a7cb"), wall: new Date(1678787937948), o: { create: "actionlog", capped: true, size: 20971520, idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.actionlog" } } }, took 500ms
2023-03-14T10:59:17.593+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-6] Refresh for collection config.system.sessions to version 8|1||641045573504a86837985c0f took 25 ms
2023-03-14T10:59:17.594+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T10:59:17.594+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T10:59:17.595+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T11:00:33.572+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:49428 #38 (15 connections now open)
2023-03-14T11:00:33.573+0100 I  NETWORK  [conn38] received client metadata from 127.0.0.1:49428 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T11:01:33.569+0100 I  NETWORK  [conn29] end connection 127.0.0.1:53112 (14 connections now open)
2023-03-14T11:04:17.576+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-7] Refresh for collection config.system.sessions from version 8|1||641045573504a86837985c0f to version 143|1||641045573504a86837985c0f took 7 ms
2023-03-14T11:08:03.544+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:49492 #39 (15 connections now open)
2023-03-14T11:08:03.545+0100 I  NETWORK  [conn39] received client metadata from 127.0.0.1:49492 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T11:09:03.543+0100 I  NETWORK  [conn38] end connection 127.0.0.1:49428 (14 connections now open)
2023-03-14T11:09:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T11:09:17.579+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T11:09:17.579+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-8] Refresh for collection config.system.sessions from version 143|1||641045573504a86837985c0f to version 282|1||641045573504a86837985c0f took 10 ms
2023-03-14T11:09:17.580+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T11:09:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T11:09:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T11:09:17.582+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T11:14:17.575+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-9] Refresh for collection config.system.sessions from version 282|1||641045573504a86837985c0f to version 422|1||641045573504a86837985c0f took 6 ms
2023-03-14T11:19:17.577+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T11:19:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T11:19:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T11:19:17.580+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-10] Refresh for collection config.system.sessions from version 422|1||641045573504a86837985c0f to version 563|1||641045573504a86837985c0f took 10 ms
2023-03-14T11:19:17.580+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T11:19:17.580+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T11:19:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T11:24:17.584+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T11:24:17.585+0100 I  SH_REFR  [ConfigServerCatalogCacheLoader-11] Refresh for collection config.system.sessions from version 563|1||641045573504a86837985c0f to version 683|1||641045573504a86837985c0f took 15 ms
2023-03-14T11:24:17.585+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T11:24:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T11:24:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T11:24:17.587+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T11:24:17.588+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T11:34:17.574+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T11:34:17.574+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T11:34:17.575+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T11:34:17.575+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T11:34:17.577+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T11:34:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T11:44:17.577+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T11:44:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T11:44:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T11:44:17.578+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T11:44:17.579+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T11:44:17.580+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T12:03:03.706+0100 I  CONNPOOL [RS] Connecting to localhost:27018
2023-03-14T12:04:03.718+0100 I  CONNPOOL [RS] Ending idle connection to host localhost:27018 because the pool meets constraints; 2 connections to that host remain open
2023-03-14T12:04:17.574+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T12:04:17.574+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T12:04:17.575+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T12:04:17.576+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T12:04:17.576+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T12:04:17.577+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T12:14:13.733+0100 I  STORAGE  [repl-writer-worker-11] createCollection: config.databases with provided UUID: 9f3723f7-8e29-4e38-b1f7-4e6c40bce2bc and options: { uuid: UUID("9f3723f7-8e29-4e38-b1f7-4e6c40bce2bc") }
2023-03-14T12:14:14.094+0100 I  INDEX    [repl-writer-worker-11] index build: done building index _id_ on ns config.databases
2023-03-14T12:14:14.095+0100 I  REPL     [repl-writer-worker-11] applied op: command { ts: Timestamp(1678792453, 2), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("9f3723f7-8e29-4e38-b1f7-4e6c40bce2bc"), wall: new Date(1678792453671), o: { create: "databases", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.databases" } } }, took 362ms
2023-03-14T12:19:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T12:19:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T12:24:17.583+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T12:24:17.583+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T12:32:37.719+0100 I  CONNPOOL [RS] Connecting to localhost:27018
2023-03-14T12:33:37.722+0100 I  CONNPOOL [RS] Ending idle connection to host localhost:27018 because the pool meets constraints; 2 connections to that host remain open
2023-03-14T12:45:52.729+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:53747 #62 (15 connections now open)
2023-03-14T12:45:52.730+0100 I  NETWORK  [conn62] received client metadata from 127.0.0.1:53747 conn62: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T12:54:52.736+0100 I  NETWORK  [conn62] end connection 127.0.0.1:53747 (14 connections now open)
2023-03-14T12:59:17.580+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T12:59:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T12:59:17.581+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T12:59:17.582+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T12:59:17.582+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T12:59:17.583+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T13:01:12.176+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:59006 #66 (15 connections now open)
2023-03-14T13:01:12.178+0100 I  NETWORK  [conn66] received client metadata from 127.0.0.1:59006 conn66: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T13:13:12.187+0100 I  NETWORK  [conn66] end connection 127.0.0.1:59006 (14 connections now open)
2023-03-14T13:17:19.880+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:50456 #67 (15 connections now open)
2023-03-14T13:17:19.881+0100 I  NETWORK  [conn67] received client metadata from 127.0.0.1:50456 conn67: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T13:22:19.885+0100 I  NETWORK  [conn67] end connection 127.0.0.1:50456 (14 connections now open)
2023-03-14T13:33:13.774+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:61223 #68 (15 connections now open)
2023-03-14T13:33:13.775+0100 I  NETWORK  [conn68] received client metadata from 127.0.0.1:61223 conn68: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T13:34:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T13:34:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T13:34:17.587+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T13:34:17.587+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T13:38:13.780+0100 I  NETWORK  [conn68] end connection 127.0.0.1:61223 (14 connections now open)
2023-03-14T13:44:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T13:44:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T13:44:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T13:44:17.587+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T13:44:17.588+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T13:44:17.588+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T13:59:17.584+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T13:59:17.585+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T13:59:17.586+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T13:59:17.587+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T13:59:17.589+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T13:59:17.589+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T14:12:02.751+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57960 #77 (15 connections now open)
2023-03-14T14:12:02.753+0100 I  NETWORK  [conn77] received client metadata from 127.0.0.1:57960 conn77: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T14:17:02.763+0100 I  NETWORK  [conn77] end connection 127.0.0.1:57960 (14 connections now open)
2023-03-14T14:30:49.607+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678800648876) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 3 } protocol:op_msg 730ms
2023-03-14T14:31:50.185+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678800709610) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 574ms
2023-03-14T14:32:50.368+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678800770189) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 4 } protocol:op_msg 179ms
2023-03-14T14:58:44.746+0100 I  REPL     [replication-31] Restarting oplog query due to error: NetworkInterfaceExceededTimeLimit: error in fetcher batch callback :: caused by :: Request 69962 timed out, deadline was 2023-03-14T14:41:56.075+0100, op was RemoteCommand 69962 -- target:[localhost:27018] db:local expDate:2023-03-14T14:41:56.075+0100 cmd:{ getMore: 4249367139098828219, collection: "oplog.rs", batchSize: 13981010, maxTimeMS: 5000, term: 1, lastKnownCommittedOpTime: { ts: Timestamp(1678801305, 3), t: 1 } }. Last fetched optime: { ts: Timestamp(1678801305, 3), t: 1 }. Restarts remaining: 1
2023-03-14T14:58:44.747+0100 I  REPL     [replication-31] Scheduled new oplog query Fetcher source: localhost:27018 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1678801305, 3) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 1, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 10000ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 69965 -- target:localhost:27018 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1678801305, 3) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 1, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2023-03-14T14:58:44.747+0100 I  CONNPOOL [RS] Connecting to localhost:27018
2023-03-14T14:58:44.748+0100 I  CONNPOOL [RS] Ending connection to host localhost:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2023-03-14T14:58:44.771+0100 I  ELECTION [replexec-95] Starting an election, since we've seen no PRIMARY in the past 10000ms
2023-03-14T14:58:44.772+0100 I  ELECTION [replexec-95] conducting a dry run election to see if we could be elected. current term: 1
2023-03-14T14:58:44.772+0100 I  REPL     [replexec-95] Scheduling remote command request for vote request: RemoteCommand 69968 -- target:localhost:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "myRepl", dryRun: true, term: 1, candidateIndex: 2, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678801305, 3), t: 1 } }
2023-03-14T14:58:44.772+0100 I  REPL     [replexec-95] Scheduling remote command request for vote request: RemoteCommand 69969 -- target:localhost:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "myRepl", dryRun: true, term: 1, candidateIndex: 2, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678801305, 3), t: 1 } }
2023-03-14T14:58:44.774+0100 I  ELECTION [replexec-91] VoteRequester(term 1 dry run) received a yes vote from localhost:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1678801305, 3), $clusterTime: { clusterTime: Timestamp(1678801305, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1678801305, 3) }
2023-03-14T14:58:44.774+0100 I  ELECTION [replexec-96] dry election run succeeded, running for election in term 2
2023-03-14T14:58:44.792+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:61092 #79 (15 connections now open)
2023-03-14T14:58:44.793+0100 I  NETWORK  [conn79] received client metadata from 127.0.0.1:61092 conn79: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T14:58:45.367+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T14:58:45.367+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T14:58:45.367+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27040 due to ShutdownInProgress: Pool for localhost:27040 has expired.
2023-03-14T14:58:47.799+0100 I  COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after electionMetrics: 0, after extra_info: 0, after flowControl: 0, after freeMonitoring: 0, after globalLock: 0, after indexBulkBuilder: 0, after locks: 0, after logicalSessionRecordCache: 0, after network: 0, after opLatencies: 2793, after opReadConcernCounters: 2793, after opcounters: 2793, after opcountersRepl: 2793, after oplogTruncation: 2794, after repl: 2794, after scramCache: 2794, after security: 2794, after shardedIndexConsistency: 2794, after shardingStatistics: 2794, after storageEngine: 2794, after tcmalloc: 2794, after trafficRecording: 2794, after transactions: 2794, after transportSecurity: 2794, after twoPhaseCommitCoordinator: 2794, after wiredTiger: 2795, at end: 2795 }
2023-03-14T14:58:47.804+0100 I  COMMAND  [shard-registry-reload] command config.shards command: find { find: "shards", $readPreference: { mode: "nearest", tags: [] }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:3 cursorExhausted:1 numYields:0 nreturned:3 reslen:508 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 2607ms
2023-03-14T14:58:47.857+0100 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: Sync source must be ahead of me. My last fetched oplog optime: { ts: Timestamp(1678801305, 3), t: 1 }, latest oplog optime of sync source: { ts: Timestamp(1678801305, 3), t: 1 }
2023-03-14T14:58:47.858+0100 I  REPL     [rsBackgroundSync] Clearing sync source localhost:27018 to choose a new one.
2023-03-14T14:58:47.858+0100 I  REPL     [rsBackgroundSync] could not find member to sync from
2023-03-14T14:58:47.909+0100 I  NETWORK  [conn39] end connection 127.0.0.1:49492 (14 connections now open)
2023-03-14T14:58:47.909+0100 I  NETWORK  [conn34] end connection 127.0.0.1:53137 (13 connections now open)
2023-03-14T14:58:47.910+0100 I  NETWORK  [conn31] end connection 127.0.0.1:53125 (12 connections now open)
2023-03-14T14:58:47.959+0100 I  NETWORK  [conn23] end connection 127.0.0.1:53057 (11 connections now open)
2023-03-14T14:58:47.960+0100 I  NETWORK  [conn27] end connection 127.0.0.1:53101 (10 connections now open)
2023-03-14T14:58:47.965+0100 I  NETWORK  [conn25] end connection 127.0.0.1:53066 (9 connections now open)
2023-03-14T14:58:48.199+0100 I  REPL     [replexec-91] Member localhost:27018 is now in state SECONDARY
2023-03-14T14:58:48.709+0100 I  ELECTION [conn79] Received vote request: { replSetRequestVotes: 1, setName: "myRepl", dryRun: false, term: 2, candidateIndex: 1, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678801305, 3), t: 1 } }
2023-03-14T14:58:48.709+0100 I  ELECTION [conn79] Sending vote response: { term: 2, voteGranted: false, reason: "already voted for another candidate (localhost:27020) this term (2)" }
2023-03-14T14:58:48.894+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678802328079) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 732ms
2023-03-14T14:58:48.894+0100 W  SHARDING [replSetDistLockPinger] Lock pinger for proc: ConfigServer was inactive for 1048499ms ms
2023-03-14T14:58:48.895+0100 I  REPL     [replexec-96] Scheduling remote command request for vote request: RemoteCommand 69980 -- target:localhost:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "myRepl", dryRun: false, term: 2, candidateIndex: 2, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678801305, 3), t: 1 } }
2023-03-14T14:58:48.896+0100 I  REPL     [replexec-96] Scheduling remote command request for vote request: RemoteCommand 69981 -- target:localhost:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "myRepl", dryRun: false, term: 2, candidateIndex: 2, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678801305, 3), t: 1 } }
2023-03-14T14:58:48.931+0100 I  ELECTION [replexec-95] VoteRequester(term 2) received a no vote from localhost:27018 with reason "already voted for another candidate (localhost:27019) this term (2)"; response message: { term: 2, voteGranted: false, reason: "already voted for another candidate (localhost:27019) this term (2)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000001') }, lastCommittedOpTime: Timestamp(1678801305, 3), $clusterTime: { clusterTime: Timestamp(1678801305, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1678801305, 3) }
2023-03-14T14:58:48.931+0100 I  ELECTION [replexec-97] VoteRequester(term 2) received a no vote from localhost:27019 with reason "already voted for another candidate (localhost:27019) this term (2)"; response message: { term: 2, voteGranted: false, reason: "already voted for another candidate (localhost:27019) this term (2)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1678801305, 3), $clusterTime: { clusterTime: Timestamp(1678801305, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1678801305, 3) }
2023-03-14T14:58:48.931+0100 I  ELECTION [replexec-98] not becoming primary, we received insufficient votes
2023-03-14T14:58:48.931+0100 I  ELECTION [replexec-98] Lost election
2023-03-14T14:58:49.257+0100 I  REPL     [replexec-95] Member localhost:27019 is now in state PRIMARY
2023-03-14T14:58:49.795+0100 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to localhost:27018: InvalidSyncSource: Sync source was cleared. Was localhost:27018
2023-03-14T14:58:50.177+0100 I  REPL     [rsBackgroundSync] sync source candidate: localhost:27019
2023-03-14T14:58:50.182+0100 I  CONNPOOL [RS] Connecting to localhost:27019
2023-03-14T14:58:50.462+0100 I  REPL     [rsBackgroundSync] Changed sync source from empty to localhost:27019
2023-03-14T14:58:59.165+0100 I  ELECTION [conn18] Received vote request: { replSetRequestVotes: 1, setName: "myRepl", dryRun: true, term: 2, candidateIndex: 0, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678802337, 2), t: 2 } }
2023-03-14T14:58:59.165+0100 I  ELECTION [conn18] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2023-03-14T14:58:59.194+0100 I  ELECTION [conn18] Received vote request: { replSetRequestVotes: 1, setName: "myRepl", dryRun: false, term: 3, candidateIndex: 0, configVersion: 2, lastCommittedOp: { ts: Timestamp(1678802337, 2), t: 2 } }
2023-03-14T14:58:59.194+0100 I  ELECTION [conn18] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2023-03-14T14:59:00.373+0100 I  REPL     [replexec-97] Member localhost:27018 is now in state PRIMARY
2023-03-14T14:59:00.374+0100 I  REPL     [replexec-98] Member localhost:27019 is now in state SECONDARY
2023-03-14T14:59:44.749+0100 I  CONNPOOL [RS] Ending idle connection to host localhost:27018 because the pool meets constraints; 1 connections to that host remain open
2023-03-14T14:59:47.791+0100 I  NETWORK  [conn8] end connection 127.0.0.1:58457 (8 connections now open)
2023-03-14T15:00:01.547+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57523 #82 (9 connections now open)
2023-03-14T15:00:01.548+0100 I  NETWORK  [conn82] received client metadata from 127.0.0.1:57523 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:01:01.548+0100 I  NETWORK  [conn79] end connection 127.0.0.1:61092 (8 connections now open)
2023-03-14T15:01:15.227+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27040
2023-03-14T15:01:15.228+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T15:01:15.228+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T15:02:37.657+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57537 #86 (9 connections now open)
2023-03-14T15:02:37.658+0100 I  NETWORK  [conn86] received client metadata from 127.0.0.1:57537 conn86: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:02:49.445+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57575 #87 (10 connections now open)
2023-03-14T15:02:49.451+0100 I  NETWORK  [conn87] received client metadata from 127.0.0.1:57575 conn87: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:02:49.469+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57576 #88 (11 connections now open)
2023-03-14T15:02:49.471+0100 I  NETWORK  [conn88] received client metadata from 127.0.0.1:57576 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:03:17.228+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57583 #89 (12 connections now open)
2023-03-14T15:03:17.231+0100 I  NETWORK  [conn89] received client metadata from 127.0.0.1:57583 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:03:48.233+0100 I  CONNPOOL [RS] Dropping all pooled connections to localhost:27018 due to ShutdownInProgress: Pool for localhost:27018 has expired.
2023-03-14T15:05:17.816+0100 I  NETWORK  [conn82] end connection 127.0.0.1:57523 (11 connections now open)
2023-03-14T15:05:18.270+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57604 #90 (12 connections now open)
2023-03-14T15:05:18.272+0100 I  NETWORK  [conn90] received client metadata from 127.0.0.1:57604 conn90: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:05:41.871+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57607 #91 (13 connections now open)
2023-03-14T15:05:41.873+0100 I  NETWORK  [conn91] received client metadata from 127.0.0.1:57607 conn91: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:06:01.928+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57612 #92 (14 connections now open)
2023-03-14T15:06:01.929+0100 I  NETWORK  [conn92] received client metadata from 127.0.0.1:57612 conn92: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:06:03.832+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:57614 #93 (15 connections now open)
2023-03-14T15:06:03.834+0100 I  NETWORK  [conn93] received client metadata from 127.0.0.1:57614 conn93: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:08:16.085+0100 I  NETWORK  [conn91] end connection 127.0.0.1:57607 (14 connections now open)
2023-03-14T15:10:50.276+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:50316 #94 (15 connections now open)
2023-03-14T15:10:50.284+0100 I  NETWORK  [conn94] received client metadata from 127.0.0.1:50316 conn94: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:13:19.215+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678803198939) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 3 } protocol:op_msg 275ms
2023-03-14T15:16:15.231+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27042 due to ShutdownInProgress: Pool for localhost:27042 has expired.
2023-03-14T15:16:15.232+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27042
2023-03-14T15:17:00.602+0100 I  NETWORK  [conn94] end connection 127.0.0.1:50316 (14 connections now open)
2023-03-14T15:18:24.694+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:54577 #96 (15 connections now open)
2023-03-14T15:18:24.695+0100 I  NETWORK  [conn96] received client metadata from 127.0.0.1:54577 conn96: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:19:58.705+0100 I  NETWORK  [conn86] end connection 127.0.0.1:57537 (14 connections now open)
2023-03-14T15:22:04.836+0100 I  NETWORK  [listener] connection accepted from 127.0.0.1:54613 #97 (15 connections now open)
2023-03-14T15:22:04.839+0100 I  NETWORK  [conn97] received client metadata from 127.0.0.1:54613 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.24" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19044)" } }
2023-03-14T15:26:15.230+0100 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to localhost:27041 due to ShutdownInProgress: Pool for localhost:27041 has expired.
2023-03-14T15:26:15.231+0100 I  CONNPOOL [TaskExecutorPool-0] Connecting to localhost:27041
2023-03-14T15:27:49.726+0100 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1678804069422) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 ok:0 errMsg:"Not primary while running findAndModify command on collection config.lockpings" errName:NotWritablePrimary errCode:10107 reslen:536 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 5 } protocol:op_msg 303ms
